{% load_yaml as defaults %}

# used in init.sls and lib.sls
container:
  service_basepath: /etc/containers/podman.service
compose:
  workdir_basepath: /etc/containers/podman-compose.service
  base_filename: docker-compose.yml
  override_filename: docker-compose.override.yml
  env_filename: .env

# part of /etc/containers/containers.conf:[engine]
engine:
  # Container Runtime: ["runc"(default), "crun"]
  # crun: alternative OCI runtime with support for cgroup V2
  runtime: "crun"
  # Directory for libpod named volumes. Default:
  volume_path: "/var/lib/containers/storage/volumes"

# part of /etc/containers/storage.conf
storage:
  # Primary storage driver
  driver: "overlay"

  # Primary Read/Write location of container storage
  graphroot: "/var/lib/containers/storage"

  # Storage path for rootless users
  rootless_storage_path : "$HOME/.local/share/containers/storage"

  # storage options
  options:
    overlay:
      mount_program: "/usr/bin/fuse-overlayfs"

# part of /etc/containers/mounts.conf
# Global Mounts: The format of the mounts.conf is the volume format /SRC:/DEST,
# one mount per line. For example, a mounts.conf with the line
# - "/usr/share/secrets:/run/secrets"
# would cause the contents of the /usr/share/secrets directory on the host
# to be mounted on the /run/secrets directory inside the container.
# Setting mountpoints allows containers to use the files of the host.
mounts: []

# /etc/containers/policy.json
# Policy: Manages which registries you trust as a source of container images based on its location.
# The location is determined by the transport and the registry host of the image.
# Using this container image docker://docker.io/library/busybox as an example,
#   docker is the transport and docker.io is the registry host.
policy: |
    { "default": [ { "type": "insecureAcceptAnything" } ],
      "transports": {
        "docker-daemon": { "": [{"type":"insecureAcceptAnything"}] }
      }
    }

{% endload %}


{% load_yaml as default_container %}
# name of the container pod and name of the controlling systemd service
name:

# enabled: if false, service will not get started and will be stopped if running
enabled: true
# absent: if enabled is false and absent is true, remove config and service files
absent: false
# update: if set true: container image will be pulled/build on every service start
update: true
# ephemeral: if set true, existing container will be removed on start
ephemeral: true
# Set the user namespace mode for the container. options are "pick","auto","host","private"
# pick is analog to systemd nspawn and computes starting host_uid based on the container name hash
userns: host
# options: dict: {key: value,} container options parameter for podman run
options: {}

instance:
  # commands run before the first time ever the service is started
  firstrun: []
  # commands run after updating image to newer image, before starting new image
  udpaterun: []

# ### systemd service options
# systemd type: "exec" or "oneshot" or advanced types: "simple, forking, dbus, notify, idle"
type: exec
# systemd restart: "no", "on-failure" or
# advanced: "on-success, on-abnormal, on-watchdog, on-abort, or always"
# default: no if type oneshot, on-failure else
restart: ""
# after, requires, wants: equal to systemd config
after: ""
requires: ""
wants: ""
# additional systemd properties
properties: {}

# name of the container image: x/y[:z]
image:
# optional tag, will be appended to image and on build
tag:
# environment: dict: {key: value,} add environment data
environment: {}
# environment will be populated with SERVICE_NAME which is constructed using servicename + "_" + profilename
# label: dict: {key: value,} add label to container
labels: {}
# storage: create volumes from list: - {name: volume_name, labels=[], driver: local, opts=[]}
storage: []
# volume: list: - [source-volume|host-dir:]container-dir[:options]
volumes: []
# ports: list
ports: []
# command: if set, will replace default command
command: ""
# args: if set, will add args for command, command must also be set
args: ""

# build: build container from source
build: false
build_source: ""
build_args: {}

{% endload %}


{% load_yaml as default_compose %}
# name of the compose sevice and name of the controlling systemd service
name:

# enabled: if false, service will not get started and will be stopped if running
enabled: true
# absent: if enabled is false and absent is true, remove config and service files
absent: false
# update: if true: container image will be pulled/build on every service start
update: true
# Set the user namespace mode for the container. options are "pick","auto","host","private"
# pick is in analogy to systemd nspawn, and will compute starting host_uid based on the container name hash
userns: host

instance:
  # commands run before the first time ever the service is started
  firstrun: []
  # commands run after updating image to newer image, before starting new image
  udpaterun: []

# ### systemd service options
# systemd restart: "no, on-failure, on-success, on-abnormal, on-watchdog, on-abort, or always"
restart: on-failure
# after, requires, wants: equal to systemd config
after: ""
requires: ""
wants: ""
# additional systemd properties
properties: {}

# environment to be placed as ".env" file inside workdir
environment: {}

# compose source config and compose overrides config
source:
config: {}

# workdir: if empty will use settings.compose.workdir_basepath+ "/"+ compose.name
workdir:

# files to be placed inside workdir
files: {}
{#
  test.file:
    source: salt://containers/test.file
    # will automatically get rendered via jinja, with environment put into context
    # files will support any file.managed attribute to be specified
  another.file:
    mode: "600"
    contents: |
      this is the content
  still.some.file:
    source: salt://containers/still.jinja
    defaults:
      custom: this is a custom var that will be available in the jinja context
#}
{% endload %}


{%- set settings = salt['grains.filter_by']({'default': defaults},
  grain='default', default= 'default', merge= salt['pillar.get']('containers', {})) %}
